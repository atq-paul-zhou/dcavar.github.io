Course: Python for Computational Linguistics
Teacher: Damir Cavar

Learning outcomes and competences
After completion of the course the student is expected to understand basic programming concepts and strategies in Python, and in particular the necessary data structures, control sequences, and implementations of programming paradigms for computational linguistic applications. The student is able to work with software development environments for Python, and to develop basic text- and language processing scripts using existing libraries and modules. Further, the student is able to use existing resources to extend future work and research in depth in both domains, i.e. programming in Python, and computational linguistic algorithms and application.

Prerequisites
Basic understanding of programming and computational linguistics.

Course content
The course is split in two major sections.
In the first section the basic properties of Python are introduced, including the following topics:
- Installing and running Python
- Variables (Integers, Floats, Strings, Lists, Tuples, Dictionaries)
- Arithmetic Expressions
- Flow control (Conditions, Loops, Functions)
- Modules
- Classes
- Input and Output
- Exceptions
In the second part of the course two types of computational linguistic paradigms are introduced on the basis of hands-on exercises and examples: a. symbolic language processing, based on rule-based parsing; b. statistical methods, based on numerical statistics and information theoretic concepts on the basis of n-gram models. The statistical section will be extended with topics from machine learning approaches to lexical acquisition and text classification (e.g. Clustering).
Parsing strategies will be based on example implementations of various parsing algorithms:
- Parsing a grammar (CFG)
- Agenda-based top-down parsing
- Agenda-based bottom-up parsing
- Incremental chart parsing
Statistical methods will be introduced via implementations of:
- Counting characters, words
- Creating frequency profiles, maximum likelihood
- N-gram models
- Language Identification
- Calculating Information theoretic measures (Entropy, Mutual Information, Relative Entropy)
Machine learning algorithms for lexical acquisition and text classification tasks will be introduced on the basis of example implementations of:
- K-means clustering
- Expectation maximization clustering
Various algorithms will be discussed on the basis of ready implementations, many concrete experiments will be implemented in groups during the class.

Required textbooks
None

Optional textbooks and online documentations
- Python.org manuals: http://www.python.org/doc/
- Dive into Python: http://diveintopython.org/
- Thinking in Python: http://www.mindview.net/Books/TIPython
- A Byte of Python: http://www.dpawson.co.uk/bop/
- How to think like a computer scientist: http://www.ibiblio.org/obp/thinkCSpy/

Lutz (1996) Programming Python, http://www.oreilly.com/catalog/python2/
Lutz and Ascher (1999) Learning Python, http://www.oreilly.com/catalog/lpython2/
Martelli (2003) Python in a Nutshell, http://www.oreilly.com/catalog/pythonian/
Martelli and Ascher (2002) Python Cookbook, http://aspn.activestate.com/ASPN/Python/Cookbook/
Lutz (1998) Python Pocket Reference, http://www.oreilly.com/catalog/pythonpr3/
	

